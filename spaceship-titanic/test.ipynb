{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree is obvious approach\n",
    "\n",
    "#nn approach\n",
    "'''\n",
    "many categorical variables\n",
    "initial option: one hot\n",
    "additional option: encodings\n",
    "'''\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "train_path = \"train.csv\"\n",
    "test_path = \"test.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "train_frame = pd.read_csv(train_path)\n",
    "test_frame = pd.read_csv(train_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
      "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
      "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
      "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
      "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
      "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
      "...          ...        ...       ...       ...            ...   ...    ...   \n",
      "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
      "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
      "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
      "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
      "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "...           ...        ...           ...     ...     ...                ...   \n",
      "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
      "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
      "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
      "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
      "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
      "\n",
      "      Transported  \n",
      "0           False  \n",
      "1            True  \n",
      "2           False  \n",
      "3           False  \n",
      "4            True  \n",
      "...           ...  \n",
      "8688        False  \n",
      "8689        False  \n",
      "8690         True  \n",
      "8691        False  \n",
      "8692         True  \n",
      "\n",
      "[8693 rows x 14 columns]\n",
      "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
      "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
      "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
      "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
      "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
      "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
      "...          ...        ...       ...       ...            ...   ...    ...   \n",
      "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
      "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
      "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
      "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
      "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "...           ...        ...           ...     ...     ...                ...   \n",
      "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
      "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
      "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
      "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
      "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
      "\n",
      "      Transported  \n",
      "0           False  \n",
      "1            True  \n",
      "2           False  \n",
      "3           False  \n",
      "4            True  \n",
      "...           ...  \n",
      "8688        False  \n",
      "8689        False  \n",
      "8690         True  \n",
      "8691        False  \n",
      "8692         True  \n",
      "\n",
      "[8693 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "print(train_frame)\n",
    "print(test_frame)\n",
    "\n",
    "# print(train_frame.describe())\n",
    "# print(test_frame.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Europa' 'Earth' 'Europa' ... 'Earth' 'Europa' 'Europa']\n",
      "(8693,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "planets = train_frame.loc[:,\"HomePlanet\"].to_numpy(na_value=\"\")\n",
    "print(planets)\n",
    "print(planets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels = 4\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(categories):\n",
    "    # Convert categories to numerical labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(categories)\n",
    "\n",
    "    # Create an identity matrix of size (n, n) where n is the number of unique labels\n",
    "    n=len(np.unique(labels))\n",
    "    print(f\"Number of unique labels = {n}\")\n",
    "    identity_matrix = np.eye(n)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_encoding = identity_matrix[labels]\n",
    "\n",
    "    return one_hot_encoding\n",
    "# Example usage\n",
    "\n",
    "oh_planets = one_hot_encode(planets)\n",
    "print(oh_planets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels = 4\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "destination = train_frame.loc[:,\"Destination\"].to_numpy(na_value=\"\")\n",
    "oh_dest = one_hot_encode(destination)\n",
    "print(oh_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels = 3\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Number of unique labels = 3\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Number of unique labels = 2\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "sleep = train_frame.loc[:,\"CryoSleep\"].to_numpy()\n",
    "oh_sleep = one_hot_encode(sleep)\n",
    "print(oh_sleep)\n",
    "vip = train_frame.loc[:,\"VIP\"].to_numpy()\n",
    "oh_vip = one_hot_encode(vip)\n",
    "print(oh_vip)\n",
    "\n",
    "transported = train_frame.loc[:,\"Transported\"].to_numpy()\n",
    "oh_transported = one_hot_encode(transported)\n",
    "print(oh_transported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin = train_frame.loc[:,\"Cabin\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels = 9\n",
      "Number of unique labels = 3\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[   0.]\n",
      " [   0.]\n",
      " [   0.]\n",
      " ...\n",
      " [1500.]\n",
      " [ 608.]\n",
      " [ 608.]] [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "list1, list2, list3 = split_arrays(cabin)\n",
    "\n",
    "oh_c1 = one_hot_encode(list1)\n",
    "oh_c2 = np.array(list2,dtype=\"float64\").reshape((8693,1))\n",
    "oh_c3 = one_hot_encode(list3)\n",
    "\n",
    "print(oh_c1,oh_c2,oh_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001_01', '0002_01', '0003_01', '0003_02', '0004_01', '0005_01', '0006_01', '0006_02', '0007_01', '0008_01', '0008_02', '0008_03', '0009_01', '0010_01', '0011_01', '0012_01', '0014_01', '0015_01', '0016_01', '0017_01', '0017_02', '0020_01', '0020_02', '0020_03', '0020_04', '0020_05', '0020_06', '0022_01', '0024_01', '0025_01', '0026_01', '0028_01', '0030_01', '0031_01', '0031_02', '0031_03', '0034_01', '0035_01', '0036_01', '0038_01', '0039_01', '0041_01', '0043_01', '0044_01', '0044_02', '0044_03', '0045_01', '0045_02', '0050_01', '0051_01']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "pid=train_frame.loc[:,\"PassengerId\"].to_list()\n",
    "print(pid[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000e+00 2.000e+00 3.000e+00 ... 9.279e+03 9.280e+03 9.280e+03] [1. 1. 1. ... 1. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "def split_arrays(arr):\n",
    "    list1, list2 = [], []\n",
    "    for s in arr:\n",
    "        try:\n",
    "            split_s = s.split('_')\n",
    "            if len(split_s) == 2:\n",
    "                list1.append(int(split_s[0]))\n",
    "                list2.append(int(split_s[1]))\n",
    "        except:\n",
    "            list1.append(10000)\n",
    "            list2.append(1)\n",
    "    return list1, list2\n",
    "    \n",
    "list1, list2= split_arrays(pid)\n",
    "\n",
    "id1= np.array(list1,dtype=\"float64\")\n",
    "id2 = np.array(list2, dtype=\"float64\")\n",
    "print(id1,id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.900e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [2.400e+01 1.090e+02 9.000e+00 2.500e+01 5.490e+02 4.400e+01]\n",
      " [5.800e+01 4.300e+01 3.576e+03 0.000e+00 6.715e+03 4.900e+01]\n",
      " ...\n",
      " [2.600e+01 0.000e+00 0.000e+00 1.872e+03 1.000e+00 0.000e+00]\n",
      " [3.200e+01 0.000e+00 1.049e+03 0.000e+00 3.530e+02 3.235e+03]\n",
      " [4.400e+01 1.260e+02 4.688e+03 0.000e+00 0.000e+00 1.200e+01]]\n",
      "(8693, 6)\n"
     ]
    }
   ],
   "source": [
    "#raw quantities\n",
    "# Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "rs=train_frame.iloc[:,[5,7,8,9,10,11]].to_numpy(dtype=\"float64\")\n",
    "print(rs)\n",
    "print(rs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 4)\n",
      "(8693, 4)\n",
      "(8693, 2)\n",
      "(8693, 9)\n",
      "(8693, 1)\n",
      "(8693, 3)\n",
      "(8693, 3)\n",
      "(8693, 3)\n"
     ]
    }
   ],
   "source": [
    "multicat=[oh_planets,oh_dest,oh_transported]\n",
    "cat=[oh_c1,oh_c2,oh_c3]\n",
    "binary=[oh_vip,oh_sleep]\n",
    "\n",
    "for layer in [multicat,cat,binary]:\n",
    "    for val in layer:\n",
    "        print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_transported[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 29)\n"
     ]
    }
   ],
   "source": [
    "res=np.concatenate((oh_planets,oh_dest,oh_transported,oh_c1,oh_c2,oh_c3,oh_vip,oh_sleep),axis=1)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BrandonFafata\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.Tensor(res).double()\n",
    "labs = torch.Tensor(oh_transported[:,1].reshape((8693,1))).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 Loss: 0.7106847507323304\n",
      "Epoch 2/25 Loss: 0.6934184537785831\n",
      "Epoch 3/25 Loss: 0.6931590887559033\n",
      "Epoch 4/25 Loss: 0.6928549652924183\n",
      "Epoch 5/25 Loss: 0.7224323660379631\n",
      "Epoch 6/25 Loss: 0.6916439803529134\n",
      "Epoch 7/25 Loss: 0.692136667768514\n",
      "Epoch 8/25 Loss: 0.6952623655331658\n",
      "Epoch 9/25 Loss: 0.6900183814830264\n",
      "Epoch 10/25 Loss: 0.6883439412965827\n",
      "Epoch 11/25 Loss: 0.6883839791829199\n",
      "Epoch 12/25 Loss: 0.6859850346095722\n",
      "Epoch 13/25 Loss: 0.6851787240000194\n",
      "Epoch 14/25 Loss: 0.6844788094777183\n",
      "Epoch 15/25 Loss: 0.7053574996503365\n",
      "Epoch 16/25 Loss: 0.6859936742099607\n",
      "Epoch 17/25 Loss: 0.6761343424479904\n",
      "Epoch 18/25 Loss: 0.6778085845155241\n",
      "Epoch 19/25 Loss: 0.7484817034185284\n",
      "Epoch 20/25 Loss: 0.6826340490569643\n",
      "Epoch 21/25 Loss: 0.6795821898860548\n",
      "Epoch 22/25 Loss: 0.6802998926477118\n",
      "Epoch 23/25 Loss: 0.678131861448068\n",
      "Epoch 24/25 Loss: 0.6777277449559376\n",
      "Epoch 25/25 Loss: 0.6774625253851196\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the network architecture\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(29, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "model = model.double()  # To make it use float64\n",
    "\n",
    "# Define the loss and the optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#\n",
    "dataset = utils.data.TensorDataset(inp,labs)\n",
    "loader = utils.data.DataLoader(dataset,batch_size=50)\n",
    "\n",
    "def train_model(model, criterion, optimizer, inputs, labels, num_epochs=25):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        losses=[]\n",
    "        for input,labels in loader:\n",
    "            # print(input.shape)\n",
    "            # print(labels.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(input)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} Loss: {np.mean(np.array(losses))}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "train_model(model,criterion,optimizer,inp,labs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74f8e97406d5e70837ce494e5999c188d7fe101de3e22029b10ab6e6cce092cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
